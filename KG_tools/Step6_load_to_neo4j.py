import os
import csv
from neo4j import GraphDatabase
from pipeline_config import STEP4_NODES_TSV, STEP4_EDGES_TSV

NODE_TSV_PATH = str(STEP4_NODES_TSV)
EDGE_TSV_PATH = str(STEP4_EDGES_TSV)
# ============== éœ€è¦ä½ ä¿®æ”¹çš„é…ç½® ==============

# 1ï¼‰Neo4j è¿žæŽ¥ä¿¡æ¯
NEO4J_URI = "neo4j://127.0.0.1:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "20011127"

# 2ï¼‰èŠ‚ç‚¹ & å…³ç³»åˆ—è¡¨ TSV è·¯å¾„
#   æ³¨æ„ï¼šè¿™é‡Œç”¨çš„æ˜¯ä½ â€œæ–° Step4â€äº§å‡ºçš„æ–‡ä»¶
# NODE_TSV_PATH = r"D:\Desktop\KG_allprocess\KG_files\Output_files\Step4_output\ç¬¬ä¸€è®²_KG_nodes.tsv"
# EDGE_TSV_PATH = r"D:\Desktop\KG_allprocess\KG_files\Output_files\Step4_output\ç¬¬ä¸€è®²_KG_edges.tsv"

# 3ï¼‰æ¯æ¬¡æ‰¹é‡å†™å…¥å¤šå°‘è¡Œ
BATCH_SIZE = 500

# ============== ä¸‹é¢ä¸€èˆ¬ä¸ç”¨æ”¹ ==============


def clear_database(driver):
    """
    å¯é€‰æ“ä½œï¼šæ¸…ç©ºå½“å‰æ•°æ®åº“æ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»
    ä½¿ç”¨å‰å…ˆç¡®è®¤æ•°æ®åº“é‡Œæ²¡æœ‰åˆ«çš„æ•°æ®ï¼
    """
    with driver.session() as session:
        session.run("MATCH (n) DETACH DELETE n")
    print("ðŸ”¥ å·²æ¸…ç©º Neo4j å½“å‰æ•°æ®åº“ï¼ˆMATCH (n) DETACH DELETE nï¼‰")


def create_constraint(driver):
    """
    ç»™ :Concept(id) å»ºå”¯ä¸€çº¦æŸï¼Œé¿å…åŒä¸€ id é‡å¤åˆ›å»ºèŠ‚ç‚¹
    """
    cypher = """
    CREATE CONSTRAINT IF NOT EXISTS
    FOR (n:Concept)
    REQUIRE n.id IS UNIQUE
    """
    with driver.session() as session:
        session.run(cypher)
    print("âœ… å·²åˆ›å»º/å­˜åœ¨å”¯ä¸€çº¦æŸï¼š(:Concept {id})")


def load_nodes(driver, tsv_path: str):
    """
    ä»Ž TSV åˆ›å»ºèŠ‚ç‚¹ï¼š
    é¢„è®¡åˆ—ï¼šnode_id, name, label, page_no, sentence_id
    """
    if not os.path.exists(tsv_path):
        raise FileNotFoundError(tsv_path)

    def _create_nodes_tx(tx, rows):
        tx.run(
            """
            UNWIND $rows AS row
            MERGE (n:Concept {id: row.node_id})
            SET n.name        = row.name,
                n.label       = row.label,
                n.page_no     = row.page_no,
                n.sentence_id = row.sentence_id
            RETURN count(*) AS _
            """,
            rows=rows,
        )

    total = 0
    batch = []

    with open(tsv_path, "r", encoding="utf-8") as f, driver.session() as session:
        reader = csv.DictReader(f, delimiter="\t")
        for row in reader:
            # page_no è½¬ intï¼Œå¤±è´¥åˆ™è®°ä¸º -1
            try:
                page_no = int(row.get("page_no", -1))
            except ValueError:
                page_no = -1

            batch.append(
                {
                    "node_id": row["node_id"],
                    "name": row["name"],
                    "label": row.get("label", "Concept"),
                    "page_no": page_no,
                    "sentence_id": row.get("sentence_id", ""),
                }
            )
            if len(batch) >= BATCH_SIZE:
                session.execute_write(_create_nodes_tx, batch)
                total += len(batch)
                print(f"ðŸ§± å·²å†™å…¥èŠ‚ç‚¹æ•°ï¼š{total}")
                batch = []

        if batch:
            session.execute_write(_create_nodes_tx, batch)
            total += len(batch)
            print(f"ðŸ§± å·²å†™å…¥èŠ‚ç‚¹æ•°ï¼š{total}")

    print(f"âœ… èŠ‚ç‚¹å¯¼å…¥å®Œæˆï¼Œæ€»æ•°ï¼š{total}")


def load_edges(driver, tsv_path: str):
    """
    ä»Ž TSV åˆ›å»ºå…³ç³»ï¼š
    é¢„è®¡åˆ—ï¼šedge_id, src_id, dst_id, relation_type, confidence, page_no, sentence_id
    """
    if not os.path.exists(tsv_path):
        raise FileNotFoundError(tsv_path)

    def _create_edges_tx(tx, rows):
        tx.run(
            """
            UNWIND $rows AS row
            MATCH (a:Concept {id: row.src_id})
            MATCH (b:Concept {id: row.dst_id})
            MERGE (a)-[r:RELATED_TO]->(b)
            SET r.type        = row.relation_type,
                r.confidence  = row.confidence,
                r.page_no     = row.page_no,
                r.sentence_id = row.sentence_id
            RETURN count(*) AS _
            """,
            rows=rows,
        )

    total = 0
    batch = []

    with open(tsv_path, "r", encoding="utf-8") as f, driver.session() as session:
        reader = csv.DictReader(f, delimiter="\t")
        for row in reader:
            try:
                page_no = int(row.get("page_no", -1))
            except ValueError:
                page_no = -1
            try:
                confidence = float(row.get("confidence", 0.0))
            except ValueError:
                confidence = 0.0

            batch.append(
                {
                    "src_id": row["src_id"],
                    "dst_id": row["dst_id"],
                    "relation_type": row.get("relation_type", "related_to"),
                    "confidence": confidence,
                    "page_no": page_no,
                    "sentence_id": row.get("sentence_id", ""),
                }
            )
            if len(batch) >= BATCH_SIZE:
                session.execute_write(_create_edges_tx, batch)
                total += len(batch)
                print(f"ðŸ”— å·²å†™å…¥å…³ç³»æ•°ï¼š{total}")
                batch = []

        if batch:
            session.execute_write(_create_edges_tx, batch)
            total += len(batch)
            print(f"ðŸ”— å·²å†™å…¥å…³ç³»æ•°ï¼š{total}")

    print(f"âœ… å…³ç³»å¯¼å…¥å®Œæˆï¼Œæ€»æ•°ï¼š{total}")


def main():
    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))

    try:
        # å¦‚éœ€æ¯æ¬¡é‡å»ºå›¾ï¼ŒæŠŠä¸‹é¢è¿™è¡Œçš„æ³¨é‡ŠåŽ»æŽ‰ï¼š
        # clear_database(driver)

        create_constraint(driver)

        print("\n=== å¼€å§‹å¯¼å…¥èŠ‚ç‚¹ ===")
        load_nodes(driver, NODE_TSV_PATH)

        print("\n=== å¼€å§‹å¯¼å…¥å…³ç³» ===")
        load_edges(driver, EDGE_TSV_PATH)

        print("\nðŸŽ‰ æ‰€æœ‰æ•°æ®å·²å¯¼å…¥ Neo4jï¼å¯ä»¥åœ¨ Browser ä¸­æ‰§è¡Œï¼š")
        print("   MATCH (n)-[r]->(m) RETURN n,r,m LIMIT 50;")
    finally:
        driver.close()


if __name__ == "__main__":
    main()
